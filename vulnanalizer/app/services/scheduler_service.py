"""
–°–µ—Ä–≤–∏—Å –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –∑–∞–¥–∞—á –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
"""
import asyncio
import schedule
import time
import csv
import json
import os
import tempfile
import tarfile
import subprocess
from datetime import datetime, timedelta
from typing import Dict, Any, Optional
from pathlib import Path
from database import get_db
from utils.file_utils import split_file_by_size, extract_compressed_file
from utils.validation_utils import is_valid_ip
from services.vm_worker import VMWorker
import traceback

class SchedulerService:
    def __init__(self):
        self.db = get_db()
        self.running = False
        self.tasks = {}
    
    async def start_scheduler(self):
        """–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫"""
        if self.running:
            return
        
        self.running = True
        print("üïê Scheduler started")
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ
        schedule.every().hour.do(self._run_async_task, self.hourly_check)
        schedule.every(30).minutes.do(self._run_async_task, self.cleanup_old_data)
        schedule.every(10).seconds.do(self._run_async_task, self.process_background_tasks)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        asyncio.create_task(self._run_scheduler())
    
    async def stop_scheduler(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫"""
        self.running = False
        schedule.clear()
        print("üïê Scheduler stopped")
    
    def _run_async_task(self, async_func):
        """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ async —Ñ—É–Ω–∫—Ü–∏–π –≤ schedule"""
        asyncio.create_task(async_func())
    
    async def _run_scheduler(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞"""
        print("üïê –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∑–∞–ø—É—â–µ–Ω, –Ω–∞—á–∏–Ω–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª")
        while self.running:
            try:
                schedule.run_pending()
                # –î–µ–ª–∞–µ–º —Ü–∏–∫–ª –±–æ–ª–µ–µ –æ—Ç–∑—ã–≤—á–∏–≤—ã–º: –ø—Ä–æ–≤–µ—Ä—è–µ–º pending –∫–∞–∂–¥—ã–µ 1 —Å–µ–∫—É–Ω–¥—É
                await asyncio.sleep(1)
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞: {e}")
                print(f"‚ùå Error details: {traceback.format_exc()}")
                await asyncio.sleep(1)  # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É
    
    async def hourly_check(self):
        """–ï–∂–µ—á–∞—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º—ã"""
        try:
            print("üîç Hourly system check")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            conn = await self.db.get_connection()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ö–æ—Å—Ç–æ–≤ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö
            hosts_without_data = await conn.fetchval("""
                SELECT COUNT(*) FROM vulnanalizer.hosts 
                WHERE epss_score IS NULL AND exploits_count IS NULL
            """)
            
            if hosts_without_data > 0:
                print(f"‚ö†Ô∏è Found {hosts_without_data} hosts without data")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
            last_update = await conn.fetchval("""
                SELECT MAX(GREATEST(epss_updated_at, exploits_updated_at, risk_updated_at)) 
                FROM vulnanalizer.hosts
            """)
            
            if last_update:
                hours_since_update = (datetime.now() - last_update).total_seconds() / 3600
                if hours_since_update > 24:
                    print(f"‚ö†Ô∏è Last update was {hours_since_update:.1f} hours ago")
            
        except Exception as e:
            print(f"‚ùå Error in hourly check: {e}")
    
    async def process_hosts_import_task(self, task_id: int, parameters: Dict[str, Any]):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ–Ω–æ–≤–æ–π –∑–∞–¥–∞—á–∏ –∏–º–ø–æ—Ä—Ç–∞ —Ö–æ—Å—Ç–æ–≤"""
        try:
            print(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–¥–∞—á–∏ –∏–º–ø–æ—Ä—Ç–∞ —Ö–æ—Å—Ç–æ–≤ {task_id}")
            print(f"üìã –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {parameters}")
            print(f"üìã –¢–∏–ø –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {type(parameters)}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏
            await self.db.update_background_task(task_id, **{
                'status': 'processing',
                'current_step': '–ù–∞—á–∞–ª–æ –∏–º–ø–æ—Ä—Ç–∞ —Ö–æ—Å—Ç–æ–≤',
                'start_time': datetime.now()
            })
            
            file_path = parameters.get('file_path')
            filename = parameters.get('filename')
            
            if not file_path or not Path(file_path).exists():
                await self.db.update_background_task(task_id, **{
                    'status': 'error',
                    'error_message': f'–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}',
                    'end_time': datetime.now()
                })
                return
            
            # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
            await self.db.update_background_task(task_id, **{
                'current_step': '–ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞'
            })
            
            with open(file_path, 'rb') as f:
                content = f.read()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –∞—Ä—Ö–∏–≤–æ–º
            is_archive = filename.lower().endswith(('.zip', '.gz', '.gzip'))
            
            if is_archive:
                await self.db.update_background_task(task_id, **{
                    'current_step': '–†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–∞'
                })
                decoded_content = extract_compressed_file(content, filename)
            else:
                decoded_content = content.decode('utf-8-sig')
            
            # –†–∞–∑–¥–µ–ª—è–µ–º —Ñ–∞–π–ª –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            decoded_size_mb = len(decoded_content.encode('utf-8')) / (1024 * 1024)
            if decoded_size_mb > 100:
                await self.db.update_background_task(task_id, **{
                    'current_step': f'–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ ({decoded_size_mb:.1f} –ú–ë)'
                })
                parts = split_file_by_size(decoded_content, 100)
                total_parts = len(parts)
            else:
                parts = [decoded_content]
                total_parts = 1
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞—Å—Ç–µ–π
            total_records = 0
            total_processed_lines = 0
            
            # –°–Ω–∞—á–∞–ª–∞ –ø–æ–¥—Å—á–∏—Ç–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ total_records
            total_expected_records = 0
            for part_content in parts:
                part_lines = part_content.splitlines()
                reader = csv.DictReader(part_lines, delimiter=';')
                total_expected_records += len(list(reader))
            
            print(f"üìä –û–∂–∏–¥–∞–µ—Ç—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ {total_expected_records} –∑–∞–ø–∏—Å–µ–π")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–¥–∞—á—É —Å –æ–±—â–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∑–∞–ø–∏—Å–µ–π
            await self.db.update_background_task(task_id, **{
                'total_records': total_expected_records,
                'processed_records': 0
            })
            
            for part_index, part_content in enumerate(parts, 1):
                await self.db.update_background_task(task_id, **{
                    'current_step': f'–û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞—Å—Ç–∏ {part_index} –∏–∑ {total_parts}',
                    'processed_items': part_index,
                    'total_items': total_parts
                })
                
                # –ü–∞—Ä—Å–∏–º CSV
                part_lines = part_content.splitlines()
                reader = csv.DictReader(part_lines, delimiter=';')
                
                part_records = []
                for row in reader:
                    try:
                        # –ü–∞—Ä—Å–∏–º hostname –∏ IP
                        host_info = row['@Host'].strip('"')
                        hostname = host_info.split(' (')[0] if ' (' in host_info else host_info
                        ip_address = host_info.split('(')[1].split(')')[0] if ' (' in host_info else ''
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å IP
                        if ip_address and not is_valid_ip(ip_address):
                            continue
                        
                        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                        cve = row['Host.@Vulners.CVEs'].strip('"')
                        criticality = row['host.UF_Criticality'].strip('"')
                        zone = row['Host.UF_Zone'].strip('"')
                        os_name = row['Host.OsName'].strip('"')
                        
                        part_records.append({
                            'hostname': hostname,
                            'ip_address': ip_address,
                            'cve': cve,
                            'cvss': None,
                            'criticality': criticality,
                            'status': 'Active',
                            'os_name': os_name,
                            'zone': zone
                        })
                        
                    except Exception as e:
                        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏: {e}")
                        continue
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
                await self.db.update_background_task(task_id, **{
                    'current_step': f'–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–∞—Å—Ç–∏ {part_index} –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö'
                })
                
                print(f"üíæ –ù–∞—á–∏–Ω–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ {len(part_records)} –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö...")
                
                # –°–æ–∑–¥–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                async def update_progress(step, message, progress_percent, current_step_progress=None, processed_records=None):
                    try:
                        print(f"üîß –í—ã–∑–æ–≤ update_progress: step={step}, message='{message}', progress_percent={progress_percent}, current_step_progress={current_step_progress}, processed_records={processed_records}")
                        
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è processed_records
                        current_processed = processed_records if processed_records is not None else 0
                        
                        print(f"üîß –í—ã—á–∏—Å–ª–µ–Ω–Ω—ã–π current_processed: {current_processed}")
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–¥–∞—á—É —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
                        update_data = {
                            'current_step': message,
                            'processed_records': current_processed,
                            'total_records': total_expected_records
                        }
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —ç—Ç–∞–ø–∞
                        if step == 'cleaning':
                            update_data['current_step'] = f"–≠—Ç–∞–ø 1/3: {message}"
                        elif step == 'inserting':
                            update_data['current_step'] = f"–≠—Ç–∞–ø 2/3: {message}"
                        elif step == 'calculating_risk':
                            # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è –æ —Ä–∞—Å—á–µ—Ç–µ —Ä–∏—Å–∫–æ–≤
                            if '–†–∞—Å—á–µ—Ç —Ä–∏—Å–∫–æ–≤...' in message:
                                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —á–∞—Å—Ç—å —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º CVE –±–µ–∑ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤
                                import re
                                match = re.search(r'–†–∞—Å—á–µ—Ç —Ä–∏—Å–∫–æ–≤\.\.\. \((\d+)/(\d+) CVE\)', message)
                                if match:
                                    current_cve = match.group(1)
                                    total_cve = match.group(2)
                                    update_data['current_step'] = f"–≠—Ç–∞–ø 3/3: –†–∞—Å—á–µ—Ç —Ä–∏—Å–∫–æ–≤... ({current_cve}/{total_cve} CVE)"
                                else:
                                    update_data['current_step'] = f"–≠—Ç–∞–ø 3/3: {message}"
                            else:
                                update_data['current_step'] = f"–≠—Ç–∞–ø 3/3: {message}"
                        elif step == 'completed':
                            update_data['current_step'] = f"‚úÖ {message}"
                        
                        await self.db.update_background_task(task_id, **update_data)
                        print(f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å –∑–∞–¥–∞—á–∏ {task_id}: {message} ({progress_percent:.1f}%) - {current_processed}/{total_expected_records}")
                    except Exception as e:
                        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: {e}")
                        import traceback
                        print(f"‚ö†Ô∏è Traceback: {traceback.format_exc()}")
                
                await self.db.insert_hosts_records_with_progress(part_records, update_progress)
                print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
                
                total_records += len(part_records)
                total_processed_lines += len(part_lines)
                
                await self.db.update_background_task(task_id, **{
                    'processed_items': part_index,
                    'total_items': total_parts,
                    'processed_records': total_records,
                    'total_records': total_records
                })
            
            # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ
            await self.db.update_background_task(task_id, **{
                'status': 'completed',
                'current_step': '–ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω',
                'processed_records': total_records,
                'total_records': total_records,
                'end_time': datetime.now()
            })
            
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            try:
                Path(file_path).unlink()
            except:
                pass
            
            print(f"‚úÖ –ò–º–ø–æ—Ä—Ç —Ö–æ—Å—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω: {total_records} –∑–∞–ø–∏—Å–µ–π")
            print(f"üéâ –ó–∞–¥–∞—á–∞ {task_id} —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ —Ö–æ—Å—Ç–æ–≤: {str(e)}"
            print(f"‚ùå {error_msg}")
            print(f"‚ùå –ó–∞–¥–∞—á–∞ {task_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–æ–π")
            
            await self.db.update_background_task(task_id, **{
                'status': 'error',
                'error_message': error_msg,
                'end_time': datetime.now()
            })

    async def process_hosts_update_task(self, task_id: int, parameters: dict):
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–¥–∞—á—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ö–æ—Å—Ç–æ–≤"""
        try:
            print(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–¥–∞—á–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ö–æ—Å—Ç–æ–≤ {task_id}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ 'processing'
            await self.db.update_background_task(task_id, **{
                'status': 'processing',
                'current_step': '–ó–∞–ø—É—Å–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Ö–æ—Å—Ç–æ–≤'
            })
            
            # –°–æ–∑–¥–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            total_updated_hosts = 0  # –°—á–µ—Ç—á–∏–∫ –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —Ö–æ—Å—Ç–æ–≤
            
            async def update_progress(status, step, **kwargs):
                nonlocal total_updated_hosts
                try:
                    # –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —Ö–æ—Å—Ç–æ–≤
                    if kwargs.get('updated_hosts', 0) > 0:
                        total_updated_hosts += kwargs.get('updated_hosts', 0)
                    
                    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                    total_cves = kwargs.get('total_cves', 0)
                    processed_cves = kwargs.get('processed_cves', 0)
                    progress_percent = 0
                    
                    if total_cves > 0:
                        progress_percent = int((processed_cves / total_cves) * 100)
                    
                    update_data = {
                        'current_step': step,
                        'total_items': total_cves,
                        'processed_items': processed_cves,
                        'total_records': kwargs.get('total_hosts', 0),
                        'updated_records': total_updated_hosts,
                        'progress_percent': progress_percent
                    }
                    
                    # –£–±–∏—Ä–∞–µ–º None –∑–Ω–∞—á–µ–Ω–∏—è
                    update_data = {k: v for k, v in update_data.items() if v is not None}
                    
                    print(f"üîÑ –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–¥–∞—á—É {task_id} —Å –¥–∞–Ω–Ω—ã–º–∏: {update_data}")
                    await self.db.update_background_task(task_id, **update_data)
                    print(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} –æ–±–Ω–æ–≤–ª–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                    print(f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å hosts_update: {step} - {processed_cves}/{total_cves} CVE ({progress_percent}%), {total_updated_hosts} —Ö–æ—Å—Ç–æ–≤ (–≤—Å–µ–≥–æ)")
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ hosts_update: {e}")
                    print(f"‚ùå –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {traceback.format_exc()}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            update_type = parameters.get('update_type', 'parallel')
            
            if update_type == 'optimized_batch':
                print(f"üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ö–æ—Å—Ç–æ–≤")
                # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Ö–æ—Å—Ç–æ–≤
                result = await self.db.hosts_update.update_hosts_complete(update_progress)
            else:
                print(f"üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è")
                # –ó–∞–ø—É—Å–∫–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Ö–æ—Å—Ç–æ–≤
                result = await self.db.hosts_update.update_hosts_complete(update_progress)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å
            if result['success']:
                await self.db.update_background_task(task_id, **{
                    'status': 'completed',
                    'current_step': '–ó–∞–≤–µ—Ä—à–µ–Ω–æ',
                    'total_items': result.get('processed_cves', 0),
                    'processed_items': result.get('processed_cves', 0),
                    'total_records': result.get('updated_count', 0),
                    'updated_records': result.get('updated_count', 0),
                    'end_time': datetime.now()
                })
                print(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ö–æ—Å—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {result.get('updated_count', 0)} –∑–∞–ø–∏—Å–µ–π")
                print(f"üìä –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {result}")
            else:
                await self.db.update_background_task(task_id, **{
                    'status': 'error',
                    'current_step': '–û—à–∏–±–∫–∞',
                    'error_message': result.get('message', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞'),
                    'end_time': datetime.now()
                })
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ö–æ—Å—Ç–æ–≤: {result.get('message', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
            
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ö–æ—Å—Ç–æ–≤: {str(e)}"
            print(f"‚ùå {error_msg}")
            
            await self.db.update_background_task(task_id, **{
                'status': 'error',
                'error_message': error_msg,
                'end_time': datetime.now()
            })
    
    async def process_background_tasks(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –∑–∞–≤–∏—Å—à–∏—Ö –∑–∞–¥–∞—á"""
        try:
            print("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏...")
            
            # –ü–æ–ª—É—á–∞–µ–º –∑–∞–¥–∞—á–∏ –≤ —Å—Ç–∞—Ç—É—Å–µ 'idle'
            idle_tasks = await self.db.get_background_tasks_by_status('idle')
            print(f"üìã –ù–∞–π–¥–µ–Ω–æ –∑–∞–¥–∞—á –≤ —Å—Ç–∞—Ç—É—Å–µ 'idle': {len(idle_tasks)}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–∏—Å—à–∏–µ –∑–∞–¥–∞—á–∏ (processing –±–æ–ª–µ–µ 10 –º–∏–Ω—É—Ç)
            stuck_tasks = await self._check_stuck_tasks()
            if stuck_tasks:
                print(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ –∑–∞–≤–∏—Å—à–∏—Ö –∑–∞–¥–∞—á: {len(stuck_tasks)}")
                for task in stuck_tasks:
                    print(f"‚ö†Ô∏è –ó–∞–≤–∏—Å—à–∞—è –∑–∞–¥–∞—á–∞ {task['id']} ({task['task_type']}): {task['current_step']}")
                    # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º –∑–∞–≤–∏—Å—à–∏–µ –∑–∞–¥–∞—á–∏
                    await self._restart_stuck_task(task)
            
            if idle_tasks:
                print(f"üìã –î–µ—Ç–∞–ª–∏ –∑–∞–¥–∞—á: {[(t['id'], t['task_type'], t['status']) for t in idle_tasks]}")
                
                for task in idle_tasks:
                    task_id = task['id']
                    task_type = task['task_type']
                    parameters_str = task.get('parameters', '{}')
                    
                    print(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É {task_id} —Ç–∏–ø–∞ {task_type}")
                    print(f"üìã –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–¥–∞—á–∏: {parameters_str}")
                    
                    # –î–µ—Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ JSON
                    import json
                    try:
                        parameters = json.loads(parameters_str) if parameters_str else {}
                        print(f"üìã –î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {parameters}")
                    except json.JSONDecodeError:
                        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –∑–∞–¥–∞—á–∏ {task_id}")
                        parameters = {}
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ 'initializing'
                    await self.db.update_background_task(task_id, **{
                        'status': 'initializing',
                        'current_step': '–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á–∏'
                    })
                    print(f"‚úÖ –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ {task_id} –æ–±–Ω–æ–≤–ª–µ–Ω –Ω–∞ 'initializing'")
                    
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–¥–∞—á—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π –∑–∞–¥–∞—á–µ
                    if task_type == 'hosts_import':
                        print(f"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–¥–∞—á–∏ –∏–º–ø–æ—Ä—Ç–∞ —Ö–æ—Å—Ç–æ–≤ {task_id} –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π –∑–∞–¥–∞—á–µ")
                        task = asyncio.create_task(self.process_hosts_import_task(task_id, parameters))
                        task.add_done_callback(lambda t: self._handle_task_completion(t, task_id, 'hosts_import'))
                    elif task_type == 'hosts_update':
                        print(f"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–¥–∞—á–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ö–æ—Å—Ç–æ–≤ {task_id} –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π –∑–∞–¥–∞—á–µ")
                        task = asyncio.create_task(self.process_hosts_update_task(task_id, parameters))
                        task.add_done_callback(lambda t: self._handle_task_completion(t, task_id, 'hosts_update'))
                    elif task_type == 'risk_calculation':
                        print(f"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–¥–∞—á–∏ —Ä–∞—Å—á–µ—Ç–∞ —Ä–∏—Å–∫–æ–≤ {task_id} –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π –∑–∞–¥–∞—á–µ")
                        task = asyncio.create_task(self.process_risk_calculation_task(task_id, parameters))
                        task.add_done_callback(lambda t: self._handle_task_completion(t, task_id, 'risk_calculation'))
                    elif task_type == 'risk_recalculation':
                        print(f"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–¥–∞—á–∏ –ø–µ—Ä–µ—Å—á–µ—Ç–∞ —Ä–∏—Å–∫–æ–≤ {task_id} –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π –∑–∞–¥–∞—á–µ")
                        task = asyncio.create_task(self.process_risk_recalculation_task(task_id, parameters))
                        task.add_done_callback(lambda t: self._handle_task_completion(t, task_id, 'risk_recalculation'))
                    elif task_type == 'backup_create':
                        print(f"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–¥–∞—á–∏ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞ {task_id} –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π –∑–∞–¥–∞—á–µ")
                        task = asyncio.create_task(self.process_backup_create_task(task_id, parameters))
                        task.add_done_callback(lambda t: self._handle_task_completion(t, task_id, 'backup_create'))
                    elif task_type == 'epss_download':
                        print(f"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–¥–∞—á–∏ –∑–∞–≥—Ä—É–∑–∫–∏ EPSS {task_id} –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π –∑–∞–¥–∞—á–µ")
                        task = asyncio.create_task(self.process_epss_download_task(task_id, parameters))
                        task.add_done_callback(lambda t: self._handle_task_completion(t, task_id, 'epss_download'))
                    elif task_type == 'vm_import':
                        print(f"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–¥–∞—á–∏ –∏–º–ø–æ—Ä—Ç–∞ VM {task_id} –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π –∑–∞–¥–∞—á–µ")
                        task = asyncio.create_task(self.process_vm_import_task(task_id, parameters))
                        task.add_done_callback(lambda t: self._handle_task_completion(t, task_id, 'vm_import'))
                    else:
                        print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –∑–∞–¥–∞—á–∏: {task_type}")
                        await self.db.update_background_task(task_id, **{
                            'status': 'error',
                            'error_message': f'–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –∑–∞–¥–∞—á–∏: {task_type}',
                            'end_time': datetime.now()
                        })
            else:
                print("üìã –ù–µ—Ç –∑–∞–¥–∞—á –≤ —Å—Ç–∞—Ç—É—Å–µ 'idle' –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                    
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á: {e}")
            print(f"‚ùå Error details: {traceback.format_exc()}")
    
    async def _check_stuck_tasks(self):
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–∞–≤–∏—Å—à–∏–µ –∑–∞–¥–∞—á–∏ (processing –±–æ–ª–µ–µ 10 –º–∏–Ω—É—Ç)"""
        try:
            conn = await self.db.get_connection()
            
            # –ò—â–µ–º –∑–∞–¥–∞—á–∏ –≤ —Å—Ç–∞—Ç—É—Å–µ processing, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –æ–±–Ω–æ–≤–ª—è–ª–∏—Å—å –±–æ–ª–µ–µ 10 –º–∏–Ω—É—Ç
            query = """
                SELECT id, task_type, status, current_step, created_at, updated_at, start_time
                FROM vulnanalizer.background_tasks 
                WHERE status IN ('processing', 'initializing')
                AND updated_at < NOW() - INTERVAL '10 minutes'
                ORDER BY updated_at ASC
            """
            stuck_tasks = await conn.fetch(query)
            return [dict(task) for task in stuck_tasks]
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–≤–∏—Å—à–∏—Ö –∑–∞–¥–∞—á: {e}")
            return []
        finally:
            await self.db.release_connection(conn)
    
    async def _restart_stuck_task(self, task):
        """–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –∑–∞–≤–∏—Å—à—É—é –∑–∞–¥–∞—á—É"""
        try:
            task_id = task['id']
            task_type = task['task_type']
            
            print(f"üîÑ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º –∑–∞–≤–∏—Å—à—É—é –∑–∞–¥–∞—á—É {task_id} ({task_type})")
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É —Å —Ç–µ–º–∏ –∂–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            parameters_str = task.get('parameters', '{}')
            import json
            try:
                parameters = json.loads(parameters_str) if parameters_str else {}
            except json.JSONDecodeError:
                parameters = {}
            
            # –û—Ç–º–µ–Ω—è–µ–º —Å—Ç–∞—Ä—É—é –∑–∞–¥–∞—á—É
            await self.db.update_background_task(task_id, **{
                'status': 'cancelled',
                'current_step': '–û—Ç–º–µ–Ω–µ–Ω–æ: –∑–∞–≤–∏—Å–ª–∞',
                'error_message': '–ó–∞–¥–∞—á–∞ –∑–∞–≤–∏—Å–ª–∞ –∏ –±—ã–ª–∞ –ø–µ—Ä–µ–∑–∞–ø—É—â–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏',
                'end_time': datetime.now()
            })
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
            new_task_id = await self.db.create_background_task(
                task_type=task_type,
                parameters=parameters,
                description=f"–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –∑–∞–≤–∏—Å—à–µ–π –∑–∞–¥–∞—á–∏ {task_id}"
            )
            
            print(f"‚úÖ –ó–∞–≤–∏—Å—à–∞—è –∑–∞–¥–∞—á–∞ {task_id} –æ—Ç–º–µ–Ω–µ–Ω–∞, —Å–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ {new_task_id}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ –∑–∞–≤–∏—Å—à–µ–π –∑–∞–¥–∞—á–∏ {task['id']}: {e}")
    
    async def cleanup_old_data(self):
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            print("üßπ Cleaning up old data")
            
            conn = await self.db.get_connection()
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á (—Å—Ç–∞—Ä—à–µ 30 –¥–Ω–µ–π)
            deleted_tasks = await conn.execute("""
                DELETE FROM vulnanalizer.background_tasks 
                WHERE created_at < NOW() - INTERVAL '30 days'
            """)
            
            print(f"‚úÖ Cleaned up old background tasks")
            
        except Exception as e:
            print(f"‚ùå Error in cleanup: {e}")
    
    async def add_custom_schedule(self, task_name: str, schedule_config: Dict[str, Any]):
        """–î–æ–±–∞–≤–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ"""
        try:
            frequency = schedule_config.get('frequency', 'daily')
            time_str = schedule_config.get('time', '02:00')
            
            if frequency == 'daily':
                schedule.every().day.at(time_str).do(self._run_custom_task, task_name)
            elif frequency == 'hourly':
                schedule.every().hour.do(self._run_custom_task, task_name)
            elif frequency == 'weekly':
                day = schedule_config.get('day', 'monday')
                schedule.every().monday.at(time_str).do(self._run_custom_task, task_name)
            
            self.tasks[task_name] = schedule_config
            print(f"‚úÖ Added custom schedule for task: {task_name}")
            
        except Exception as e:
            print(f"‚ùå Error adding custom schedule: {e}")
    
    async def _run_custom_task(self, task_name: str):
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫—É—é –∑–∞–¥–∞—á—É"""
        try:
            print(f"üîÑ Running custom task: {task_name}")
            
            if task_name == 'full_update':
                # –ü–æ–ª–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
                result = await self.db.update_hosts_complete()
            elif task_name == 'incremental_update':
                # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
                days = self.tasks.get(task_name, {}).get('days_old', 1)
                result = await self.db.update_hosts_incremental(days_old=days)
            else:
                print(f"‚ö†Ô∏è Unknown custom task: {task_name}")
                return
            
            print(f"‚úÖ Custom task {task_name} completed")
            
        except Exception as e:
            print(f"‚ùå Error in custom task {task_name}: {e}")

    def _handle_task_completion(self, task, task_id: int, task_type: str):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏"""
        try:
            if task.cancelled():
                print(f"‚ö†Ô∏è –ó–∞–¥–∞—á–∞ {task_id} ({task_type}) –±—ã–ª–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞")
            elif task.exception():
                error = task.exception()
                print(f"‚ùå –ó–∞–¥–∞—á–∞ {task_id} ({task_type}) –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–æ–π: {error}")
                # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –≤ –ë–î
                asyncio.create_task(self._update_task_error_status(task_id, str(error)))
            else:
                result = task.result()
                print(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} ({task_type}) —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ {task_id}: {e}")

    async def _update_task_error_status(self, task_id: int, error_message: str):
        """–û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ –Ω–∞ error"""
        try:
            await self.db.update_background_task(task_id, **{
                'status': 'error',
                'error_message': error_message,
                'end_time': datetime.now()
            })
            print(f"‚úÖ –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ {task_id} –æ–±–Ω–æ–≤–ª–µ–Ω –Ω–∞ error")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏ {task_id}: {e}")

    async def process_risk_calculation_task(self, task_id: int, parameters: Dict[str, Any]):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ —Ä–∞—Å—á–µ—Ç–∞ —Ä–∏—Å–∫–æ–≤ –¥–ª—è —Ö–æ—Å—Ç–æ–≤ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            print(f"üîç –ù–∞—á–∏–Ω–∞–µ–º —Ä–∞—Å—á–µ—Ç —Ä–∏—Å–∫–æ–≤ –¥–ª—è —Ö–æ—Å—Ç–æ–≤ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö (–∑–∞–¥–∞—á–∞ {task_id})")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ 'processing'
            await self.db.update_background_task(task_id, **{
                'status': 'processing',
                'current_step': '–ü–æ–∏—Å–∫ —Ö–æ—Å—Ç–æ–≤ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö EPSS –∏ Risk',
                'start_time': datetime.now()
            })
            
            # –ü–æ–ª—É—á–∞–µ–º —Ö–æ—Å—Ç—ã –±–µ–∑ EPSS –∏ Risk –¥–∞–Ω–Ω—ã—Ö
            conn = await self.db.get_connection()
            
            # –ù–∞—Ö–æ–¥–∏–º CVE —Ö–æ—Å—Ç–æ–≤ –±–µ–∑ EPSS –¥–∞–Ω–Ω—ã—Ö
            cve_query = """
                SELECT DISTINCT h.cve 
                FROM vulnanalizer.hosts h 
                LEFT JOIN vulnanalizer.epss e ON h.cve = e.cve 
                WHERE h.cve IS NOT NULL AND h.cve != '' 
                AND (h.epss_score IS NULL OR h.risk_score IS NULL)
                AND e.cve IS NOT NULL
                ORDER BY h.cve
            """
            cve_rows = await conn.fetch(cve_query)
            
            if not cve_rows:
                print("‚úÖ –ù–µ—Ç —Ö–æ—Å—Ç–æ–≤ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ä–∏—Å–∫–æ–≤")
                await self.db.update_background_task(task_id, **{
                    'status': 'completed',
                    'current_step': '–ù–µ—Ç —Ö–æ—Å—Ç–æ–≤ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ä–∏—Å–∫–æ–≤',
                    'end_time': datetime.now()
                })
                return
            
            total_cves = len(cve_rows)
            print(f"üîç –ù–∞–π–¥–µ–Ω–æ {total_cves} CVE –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ä–∏—Å–∫–æ–≤")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            await self.db.update_background_task(task_id, **{
                'total_items': total_cves,
                'current_step': f'–ù–∞–π–¥–µ–Ω–æ {total_cves} CVE –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ä–∏—Å–∫–æ–≤'
            })
            
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            settings_query = "SELECT key, value FROM vulnanalizer.settings"
            settings_rows = await conn.fetch(settings_query)
            settings = {row['key']: row['value'] for row in settings_rows}
            
            # –°–æ–∑–¥–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            async def update_progress(step: str, message: str, progress_percent: int = 0, **kwargs):
                await self.db.update_background_task(task_id, **{
                    'current_step': message,
                    'progress_percent': progress_percent,
                    'processed_items': kwargs.get('processed_cves', 0),
                    'total_items': total_cves,
                    'processed_records': kwargs.get('updated_hosts', 0)
                })
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ö–æ—Å—Ç–æ–≤
            await self.db.risk_calculation.update_hosts_complete(update_progress)
            
            # –ó–∞–≤–µ—Ä—à–∞–µ–º –∑–∞–¥–∞—á—É
            await self.db.update_background_task(task_id, **{
                'status': 'completed',
                'current_step': f'–†–∞—Å—á–µ—Ç —Ä–∏—Å–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è {total_cves} CVE',
                'end_time': datetime.now()
            })
            
            print(f"‚úÖ –†–∞—Å—á–µ—Ç —Ä–∏—Å–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è {total_cves} CVE")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Ä–∏—Å–∫–æ–≤: {e}")
            print(f"‚ùå Error details: {traceback.format_exc()}")
            
            await self.db.update_background_task(task_id, **{
                'status': 'error',
                'current_step': '–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Ä–∏—Å–∫–æ–≤',
                'error_message': str(e),
                'end_time': datetime.now()
            })

    async def process_risk_recalculation_task(self, task_id: int, parameters: Dict[str, Any]):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ –ø–µ—Ä–µ—Å—á–µ—Ç–∞ —Ä–∏—Å–∫–æ–≤ –¥–ª—è –í–°–ï–• —Ö–æ—Å—Ç–æ–≤"""
        try:
            print(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ—Å—á–µ—Ç —Ä–∏—Å–∫–æ–≤ –¥–ª—è –í–°–ï–• —Ö–æ—Å—Ç–æ–≤ (–∑–∞–¥–∞—á–∞ {task_id})")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ 'processing'
            await self.db.update_background_task(task_id, **{
                'status': 'processing',
                'current_step': '–ü–æ–∏—Å–∫ –≤—Å–µ—Ö —Ö–æ—Å—Ç–æ–≤ –¥–ª—è –ø–µ—Ä–µ—Å—á–µ—Ç–∞ —Ä–∏—Å–∫–æ–≤',
                'start_time': datetime.now()
            })
            
            # –ü–æ–ª—É—á–∞–µ–º –í–°–ï —Ö–æ—Å—Ç—ã —Å CVE
            conn = await self.db.get_connection()
            
            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ CVE —Ö–æ—Å—Ç–æ–≤
            cve_query = """
                SELECT DISTINCT h.cve 
                FROM vulnanalizer.hosts h 
                WHERE h.cve IS NOT NULL AND h.cve != '' 
                ORDER BY h.cve
            """
            cve_rows = await conn.fetch(cve_query)
            
            if not cve_rows:
                print("‚úÖ –ù–µ—Ç —Ö–æ—Å—Ç–æ–≤ –¥–ª—è –ø–µ—Ä–µ—Å—á–µ—Ç–∞ —Ä–∏—Å–∫–æ–≤")
                await self.db.update_background_task(task_id, **{
                    'status': 'completed',
                    'current_step': '–ù–µ—Ç —Ö–æ—Å—Ç–æ–≤ –¥–ª—è –ø–µ—Ä–µ—Å—á–µ—Ç–∞ —Ä–∏—Å–∫–æ–≤',
                    'end_time': datetime.now()
                })
                return
            
            total_cves = len(cve_rows)
            print(f"üîç –ù–∞–π–¥–µ–Ω–æ {total_cves} CVE –¥–ª—è –ø–µ—Ä–µ—Å—á–µ—Ç–∞ —Ä–∏—Å–∫–æ–≤")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            await self.db.update_background_task(task_id, **{
                'total_items': total_cves,
                'current_step': f'–ù–∞–π–¥–µ–Ω–æ {total_cves} CVE –¥–ª—è –ø–µ—Ä–µ—Å—á–µ—Ç–∞ —Ä–∏—Å–∫–æ–≤'
            })
            
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            settings_query = "SELECT key, value FROM vulnanalizer.settings"
            settings_rows = await conn.fetch(settings_query)
            settings = {row['key']: row['value'] for row in settings_rows}
            
            # –°–æ–∑–¥–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            async def update_progress(step: str, message: str, progress_percent: int = 0, **kwargs):
                await self.db.update_background_task(task_id, **{
                    'current_step': message,
                    'progress_percent': progress_percent,
                    'processed_items': kwargs.get('processed_cves', 0),
                    'total_items': total_cves,
                    'processed_records': kwargs.get('updated_hosts', 0)
                })
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–µ—Ä–µ—Å—á–µ—Ç–∞ —Ä–∏—Å–∫–æ–≤
            from database.hosts_update_service import HostsUpdateService
            hosts_update_service = HostsUpdateService()
            await hosts_update_service.recalculate_all_risks(update_progress)
            
            # –ó–∞–≤–µ—Ä—à–∞–µ–º –∑–∞–¥–∞—á—É
            await self.db.update_background_task(task_id, **{
                'status': 'completed',
                'current_step': f'–ü–µ—Ä–µ—Å—á–µ—Ç —Ä–∏—Å–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è {total_cves} CVE',
                'end_time': datetime.now()
            })
            
            print(f"‚úÖ –ü–µ—Ä–µ—Å—á–µ—Ç —Ä–∏—Å–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è {total_cves} CVE")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ—Å—á–µ—Ç–∞ —Ä–∏—Å–∫–æ–≤: {e}")
            print(f"‚ùå Error details: {traceback.format_exc()}")
            
            await self.db.update_background_task(task_id, **{
                'status': 'error',
                'current_step': '–û—à–∏–±–∫–∞ –ø–µ—Ä–µ—Å—á–µ—Ç–∞ —Ä–∏—Å–∫–æ–≤',
                'error_message': str(e),
                'end_time': datetime.now()
            })

    async def process_backup_create_task(self, task_id: int, parameters: Dict[str, Any]):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞"""
        try:
            print(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –¥–ª—è –∑–∞–¥–∞—á–∏ {task_id}")
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            tables = parameters.get('tables', [])
            include_schema = parameters.get('include_schema', True)
            include_data = parameters.get('include_data', True)
            
            if not tables:
                raise ValueError("–ù–µ –≤—ã–±—Ä–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –±—ç–∫–∞–ø–∞")
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
            backup_dir = os.getenv('BACKUP_DIR', './backups')
            try:
                os.makedirs(backup_dir, exist_ok=True)
            except PermissionError:
                # –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä–∞–≤ –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ –≤ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º /tmp
                backup_dir = '/tmp/backups'
                os.makedirs(backup_dir, exist_ok=True)
            
            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è –±—ç–∫–∞–ø–∞
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_id = f"backup_{timestamp}"
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            await self.db.update_background_task(task_id, **{
                'status': 'processing',
                'current_step': '–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ —Å–æ–∑–¥–∞–Ω–∏—é –±—ç–∫–∞–ø–∞',
                'progress_percent': 10
            })
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            with tempfile.TemporaryDirectory() as temp_dir:
                backup_file = os.path.join(temp_dir, f"{backup_id}.sql")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
                await self.db.update_background_task(task_id, **{
                    'current_step': '–°–æ–∑–¥–∞–Ω–∏–µ SQL –¥–∞–º–ø–∞',
                    'progress_percent': 30
                })
                
                # –°–æ–∑–¥–∞–µ–º SQL –¥–∞–º–ø —á–µ—Ä–µ–∑ pg_dump
                print(f"üîÑ –°–æ–∑–¥–∞–µ–º SQL –¥–∞–º–ø –¥–ª—è —Ç–∞–±–ª–∏—Ü: {tables}")
                
                # –°–æ–∑–¥–∞–µ–º SQL –¥–∞–º–ø —á–µ—Ä–µ–∑ –ø—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥ —Å asyncpg –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
                print(f"üîÑ –°–æ–∑–¥–∞–µ–º SQL –¥–∞–º–ø –¥–ª—è —Ç–∞–±–ª–∏—Ü: {tables}")
                
                # –ü–æ–ª—É—á–∞–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
                conn = await self.db.get_connection()
                
                try:
                    sql_content = []
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                    sql_content.append("-- Backup created by STools with pg_dump-style output")
                    sql_content.append(f"-- Created at: {datetime.now().isoformat()}")
                    sql_content.append(f"-- Tables: {', '.join(tables)}")
                    sql_content.append("")
                    
                    # –î–ª—è –∫–∞–∂–¥–æ–π —Ç–∞–±–ª–∏—Ü—ã —Å–æ–∑–¥–∞–µ–º –¥–∞–º–ø –≤ —Å—Ç–∏–ª–µ pg_dump
                    for table in tables:
                        schema, table_name = table.split(".", 1) if "." in table else ("public", table)
                        
                        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã
                        structure_query = f"""
                        SELECT 
                            c.column_name, 
                            c.data_type, 
                            c.is_nullable, 
                            c.column_default,
                            c.character_maximum_length,
                            c.numeric_precision,
                            c.numeric_scale,
                            c.generation_expression
                        FROM information_schema.columns c
                        WHERE c.table_schema = '{schema}' AND c.table_name = '{table_name}'
                        ORDER BY c.ordinal_position;
                        """
                        
                        structure_result = await conn.fetch(structure_query)
                        
                        if structure_result:
                            # –°–æ–∑–¥–∞–µ–º DROP TABLE
                            sql_content.append(f"DROP TABLE IF EXISTS {schema}.{table_name} CASCADE;")
                            sql_content.append("")
                            
                            # –°–æ–∑–¥–∞–µ–º CREATE TABLE
                            columns = []
                            for col in structure_result:
                                # –ë–∞–∑–æ–≤—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö
                                data_type = col['data_type']
                                
                                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è —Ç–∏–ø–æ–≤
                                if col['character_maximum_length'] and data_type in ['character varying', 'varchar', 'char']:
                                    data_type += f"({col['character_maximum_length']})"
                                elif col['numeric_precision'] and col['numeric_scale'] and data_type in ['numeric', 'decimal']:
                                    data_type += f"({col['numeric_precision']},{col['numeric_scale']})"
                                elif col['numeric_precision'] and data_type in ['numeric', 'decimal']:
                                    data_type += f"({col['numeric_precision']})"
                                
                                # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∑–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞
                                column_name = col['column_name']
                                if column_name.lower() in ['references', 'order', 'group', 'user', 'table', 'index']:
                                    column_name = f'"{column_name}"'
                                
                                col_def = f"{column_name} {data_type}"
                                
                                # NOT NULL
                                if col['is_nullable'] == 'NO':
                                    col_def += " NOT NULL"
                                
                                # DEFAULT (–Ω–æ –Ω–µ –¥–ª—è SERIAL –ø–æ–ª–µ–π)
                                if col['column_default'] and not col['column_default'].startswith('nextval'):
                                    col_def += f" DEFAULT {col['column_default']}"
                                elif col['column_default'] and col['column_default'].startswith('nextval'):
                                    # –î–ª—è SERIAL –ø–æ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º SERIAL –≤–º–µ—Å—Ç–æ integer + nextval
                                    if data_type == 'integer' and col['column_name'] == 'id':
                                        col_def = f"{column_name} SERIAL PRIMARY KEY"
                                
                                # GENERATED ALWAYS AS
                                if col['generation_expression']:
                                    col_def += f" GENERATED ALWAYS AS ({col['generation_expression']}) STORED"
                                
                                columns.append(col_def)
                            
                            sql_content.append(f"CREATE TABLE {schema}.{table_name} (")
                            sql_content.append("    " + ",\n    ".join(columns))
                            sql_content.append(");")
                            sql_content.append("")
                            
                            # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤–∏—á–Ω—ã–µ –∫–ª—é—á–∏
                            pk_query = f"""
                            SELECT kcu.column_name
                            FROM information_schema.table_constraints tc
                            JOIN information_schema.key_column_usage kcu 
                                ON tc.constraint_name = kcu.constraint_name
                            WHERE tc.table_schema = '{schema}' 
                                AND tc.table_name = '{table_name}'
                                AND tc.constraint_type = 'PRIMARY KEY'
                            ORDER BY kcu.ordinal_position;
                            """
                            
                            pk_result = await conn.fetch(pk_query)
                            if pk_result:
                                pk_columns = [row['column_name'] for row in pk_result]
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ PRIMARY KEY —É–∂–µ –≤ CREATE TABLE (–¥–ª—è SERIAL –ø–æ–ª–µ–π)
                                has_serial_pk = any(col['column_name'] == 'id' and col['column_default'] and col['column_default'].startswith('nextval') for col in structure_result)
                                
                                if not has_serial_pk:
                                    sql_content.append(f"ALTER TABLE ONLY {schema}.{table_name}")
                                    sql_content.append(f"    ADD CONSTRAINT {table_name}_pkey PRIMARY KEY ({', '.join(pk_columns)});")
                                    sql_content.append("")
                            
                            # –ü–æ–ª—É—á–∞–µ–º UNIQUE –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
                            unique_query = f"""
                            SELECT tc.constraint_name, kcu.column_name
                            FROM information_schema.table_constraints tc
                            JOIN information_schema.key_column_usage kcu 
                                ON tc.constraint_name = kcu.constraint_name
                            WHERE tc.table_schema = '{schema}' 
                                AND tc.table_name = '{table_name}'
                                AND tc.constraint_type = 'UNIQUE'
                            ORDER BY tc.constraint_name, kcu.ordinal_position;
                            """
                            
                            unique_result = await conn.fetch(unique_query)
                            if unique_result:
                                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ constraint_name
                                unique_constraints = {}
                                for row in unique_result:
                                    constraint_name = row['constraint_name']
                                    if constraint_name not in unique_constraints:
                                        unique_constraints[constraint_name] = []
                                    unique_constraints[constraint_name].append(row['column_name'])
                                
                                # –î–æ–±–∞–≤–ª—è–µ–º UNIQUE –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
                                for constraint_name, columns in unique_constraints.items():
                                    sql_content.append(f"ALTER TABLE ONLY {schema}.{table_name}")
                                    sql_content.append(f"    ADD CONSTRAINT {constraint_name} UNIQUE ({', '.join(columns)});")
                                    sql_content.append("")
                            
                            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ, –∏—Å–∫–ª—é—á–∞—è generated columns
                            non_generated_columns = []
                            for col in structure_result:
                                if not col['generation_expression']:
                                    non_generated_columns.append(col['column_name'])
                            
                            if non_generated_columns:
                                # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∏–º–µ–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
                                escaped_columns = []
                                for col in non_generated_columns:
                                    if col.lower() in ['references', 'order', 'group', 'select', 'from', 'where', 'table', 'index', 'constraint']:
                                        escaped_columns.append(f'"{col}"')
                                    else:
                                        escaped_columns.append(col)
                                columns_list = ', '.join(escaped_columns)
                                data_query = f"SELECT {columns_list} FROM {schema}.{table_name};"
                                data_result = await conn.fetch(data_query)
                                
                                if data_result:
                                    # –°–æ–∑–¥–∞–µ–º INSERT statements
                                    for row in data_result:
                                        values = []
                                        for value in row.values():
                                            if value is None:
                                                values.append("NULL")
                                            elif isinstance(value, str):
                                                # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
                                                escaped_value = value.replace("\\", "\\\\").replace("'", "''").replace("\n", "\\n").replace("\r", "\\r").replace("\t", "\\t")
                                                values.append(f"'{escaped_value}'")
                                            elif isinstance(value, (int, float)):
                                                values.append(str(value))
                                            elif isinstance(value, bool):
                                                values.append("TRUE" if value else "FALSE")
                                            else:
                                                # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É –∏ —ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º
                                                escaped_value = str(value).replace("\\", "\\\\").replace("'", "''").replace("\n", "\\n").replace("\r", "\\r").replace("\t", "\\t")
                                                values.append(f"'{escaped_value}'")
                                        
                                        sql_content.append(f"INSERT INTO {schema}.{table_name} ({columns_list}) VALUES ({', '.join(values)});")
                                
                                sql_content.append("")
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º SQL –≤ —Ñ–∞–π–ª
                    with open(backup_file, 'w', encoding='utf-8') as f:
                        f.write('\n'.join(sql_content))
                    
                    print(f"‚úÖ SQL –¥–∞–º–ø —Å–æ–∑–¥–∞–Ω: {backup_file}")
                        
                finally:
                    await self.db.release_connection(conn)
                
                # pg_dump —É–∂–µ —Å–æ–∑–¥–∞–ª —Ñ–∞–π–ª, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–ª—Å—è
                if not os.path.exists(backup_file) or os.path.getsize(backup_file) == 0:
                    raise Exception("–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞: —Ñ–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–∑–¥–∞–Ω")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
                await self.db.update_background_task(task_id, **{
                    'current_step': '–ê—Ä—Ö–∏–≤–∞—Ü–∏—è –±—ç–∫–∞–ø–∞',
                    'progress_percent': 70
                })
                
                # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤
                archive_path = os.path.join(backup_dir, f"{backup_id}.tar.gz")
                with tarfile.open(archive_path, "w:gz") as tar:
                    tar.add(backup_file, arcname=f"{backup_id}.sql")
                
                # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –±—ç–∫–∞–ø–∞
                metadata = {
                    "id": backup_id,
                    "filename": f"{backup_id}.tar.gz",
                    "size": os.path.getsize(archive_path),
                    "created_at": datetime.now().isoformat(),
                    "tables": tables,
                    "status": "completed",
                    "includes_schema": True,
                    "includes_constraints": True,
                    "includes_indexes": True,
                    "includes_primary_keys": True,
                    "backup_type": "selective_with_schema"
                }
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                metadata_file = os.path.join(backup_dir, f"{backup_id}.json")
                with open(metadata_file, 'w') as f:
                    json.dump(metadata, f, indent=2)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
                await self.db.update_background_task(task_id, **{
                    'status': 'completed',
                    'current_step': '–ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ',
                    'progress_percent': 100,
                    'end_time': datetime.now(),
                    'result_data': {
                        'backup_id': backup_id,
                        'filename': f"{backup_id}.tar.gz",
                        'size': os.path.getsize(archive_path),
                        'tables': tables
                    }
                })
                
                print(f"‚úÖ –ë—ç–∫–∞–ø {backup_id} —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ")
                print(f"üìÅ –§–∞–π–ª: {archive_path}")
                print(f"üìä –†–∞–∑–º–µ—Ä: {os.path.getsize(archive_path)} –±–∞–π—Ç")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞: {e}")
            print(f"‚ùå Error details: {traceback.format_exc()}")
            
            await self.db.update_background_task(task_id, **{
                'status': 'error',
                'current_step': '–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞',
                'error_message': str(e),
                'end_time': datetime.now()
            })

    async def process_epss_download_task(self, task_id: int, parameters: Dict[str, Any]):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ –∑–∞–≥—Ä—É–∑–∫–∏ EPSS –¥–∞–Ω–Ω—ã—Ö"""
        try:
            print(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É EPSS –¥–ª—è –∑–∞–¥–∞—á–∏ {task_id}")
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            url = parameters.get('url', 'https://epss.empiricalsecurity.com/epss_scores-current.csv.gz')
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏
            await self.db.update_background_task(task_id, **{
                'status': 'processing',
                'current_step': '–ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É EPSS –¥–∞–Ω–Ω—ã—Ö',
                'start_time': datetime.now()
            })
            
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–æ–¥—É–ª–∏
            import aiohttp
            import gzip
            import io
            import csv
            
            print(f"üì• Downloading EPSS from {url}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ –Ω–∞—á–∞–ª–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
            await self.db.update_background_task(task_id, **{
                'current_step': '–°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞',
                'progress_percent': 10
            })
            
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç—ã –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
            timeout = aiohttp.ClientTimeout(total=300, connect=60)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.get(url) as resp:
                    if resp.status != 200:
                        raise Exception(f"Failed to download: {resp.status} - {resp.reason}")
                    
                    print("üì¶ Reading compressed content...")
                    gz_content = await resp.read()
                    print(f"üìä Downloaded {len(gz_content)} bytes")
            
            await self.db.update_background_task(task_id, **{
                'current_step': '–†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö',
                'progress_percent': 15
            })
            
            print("üîì Decompressing content...")
            with gzip.GzipFile(fileobj=io.BytesIO(gz_content)) as gz:
                decoded = gz.read().decode('utf-8').splitlines()
            
            print(f"üìÑ Decompressed {len(decoded)} lines")
            
            # –ò—â–µ–º —Å—Ç—Ä–æ–∫—É —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)
            header_line = None
            for i, line in enumerate(decoded):
                if line.startswith('cve,') or 'cve' in line.split(',')[0]:
                    header_line = i
                    break
            
            if header_line is None:
                raise Exception("Could not find header line with 'cve' column")
            
            print(f"üìã Found header at line {header_line}")
            
            # –°–æ–∑–¥–∞–µ–º CSV reader –Ω–∞—á–∏–Ω–∞—è —Å –Ω–∞–π–¥–µ–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            reader = csv.DictReader(decoded[header_line:])
            
            print("üîÑ Processing CSV records...")
            records = []
            processed_count = 0
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ –Ω–∞—á–∞–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            await self.db.update_background_task(task_id, **{
                'current_step': '–û–±—Ä–∞–±–æ—Ç–∫–∞ CSV –∑–∞–ø–∏—Å–µ–π',
                'progress_percent': 20
            })
            
            for row in reader:
                try:
                    records.append({
                        'cve': row['cve'],
                        'epss': float(row['epss']),
                        'percentile': float(row['percentile']),
                        'cvss': None,  # –ü–æ–ª–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ EPSS
                        'date': None   # –ü–æ–ª–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ EPSS
                    })
                    processed_count += 1
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10000 –∑–∞–ø–∏—Å–µ–π
                    if processed_count % 10000 == 0:
                        print(f"üìä Processed {processed_count} records...")
                        progress_percent = int((processed_count / len(records)) * 100) if records else 0
                        await self.db.update_background_task(task_id, **{
                            'current_step': f'–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count} –∑–∞–ø–∏—Å–µ–π',
                            'processed_records': processed_count,
                            'progress_percent': progress_percent
                        })
                        
                except (ValueError, KeyError) as e:
                    print(f"‚ö†Ô∏è Skipping invalid row: {e}, row data: {row}")
                    continue
            
            print(f"‚úÖ Processed {len(records)} valid records")
            
            await self.db.update_background_task(task_id, **{
                'current_step': '–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö',
                'total_records': len(records),
                'processed_records': len(records),
                'progress_percent': 80
            })
            
            print("üíæ Inserting records into database...")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
            from database.epss_repository import EPSSRepository
            epss_repo = EPSSRepository()
            await epss_repo.insert_records(records)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ—Å–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            await self.db.update_background_task(task_id, **{
                'current_step': '–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏',
                'progress_percent': 95
            })
            
            print("üéâ EPSS download and processing completed successfully")
            
            # –ó–∞–≤–µ—Ä—à–∞–µ–º –∑–∞–¥–∞—á—É
            await self.db.update_background_task(task_id, **{
                'status': 'completed',
                'current_step': '–ó–∞–≥—Ä—É–∑–∫–∞ EPSS –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ',
                'processed_records': len(records),
                'progress_percent': 100,
                'end_time': datetime.now()
            })
            
        except Exception as e:
            print(f"Error in process_epss_download_task: {e}")
            await self.db.update_background_task(task_id, **{
                'status': 'error',
                'current_step': '–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ EPSS',
                'error_message': str(e),
                'end_time': datetime.now()
            })

    async def process_vm_import_task(self, task_id: int, parameters: Dict[str, Any]):
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–¥–∞—á—É –∏–º–ø–æ—Ä—Ç–∞ VM –¥–∞–Ω–Ω—ã—Ö"""
        try:
            print(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–¥–∞—á–∏ –∏–º–ø–æ—Ä—Ç–∞ VM {task_id}")
            
            # –°–æ–∑–¥–∞–µ–º VM Worker
            vm_worker = VMWorker()
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –∏–º–ø–æ—Ä—Ç
            result = await vm_worker.start_import(task_id, parameters)
            
            if result.get('success'):
                print(f"‚úÖ –ò–º–ø–æ—Ä—Ç VM –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ: {result.get('count', 0)} —Ö–æ—Å—Ç–æ–≤")
            else:
                print(f"‚ùå –ò–º–ø–æ—Ä—Ç VM –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω —Å –æ—à–∏–±–∫–æ–π: {result.get('message', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ process_vm_import_task: {e}")
            print(f"‚ùå Traceback: {traceback.format_exc()}")
            
            await self.db.update_background_task(task_id, **{
                'status': 'error',
                'current_step': '–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ VM –¥–∞–Ω–Ω—ã—Ö',
                'error_message': str(e),
                'end_time': datetime.now()
            })

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞
scheduler_service = SchedulerService()
