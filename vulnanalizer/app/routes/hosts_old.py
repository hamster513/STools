"""
–†–æ—É—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ö–æ—Å—Ç–∞–º–∏
"""
import csv
import traceback
import asyncio
import os
import uuid
from datetime import datetime
from typing import Optional
from fastapi import APIRouter, HTTPException, File, UploadFile, Query
from fastapi.responses import StreamingResponse
from starlette.responses import FileResponse

from utils.file_utils import split_file_by_size, extract_compressed_file
from utils.validation_utils import is_valid_ip
from utils.progress_utils import update_import_progress, estimate_remaining_time, import_progress
from services.risk_service import calculate_risk_score
from services.excel_service import create_excel_file
from database import get_db

router = APIRouter()


@router.post("/api/hosts/upload")
async def upload_hosts(file: UploadFile = File(...)):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –∏ —Å–æ–∑–¥–∞—Ç—å —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    try:
        print(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∞–π–ª–∞: {file.filename} ({file.size} –±–∞–π—Ç)")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (–º–∞–∫—Å–∏–º—É–º 1GB –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏)
        if file.size and file.size > 1024 * 1024 * 1024:  # 1GB
            error_msg = "–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 1GB."
            raise HTTPException(status_code=400, detail=error_msg)
        
        # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        import uuid
        file_id = str(uuid.uuid4())
        file_extension = os.path.splitext(file.filename)[1] if file.filename else '.csv'
        safe_filename = f"{file_id}{file_extension}"
        
        # –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –≤ –≤–æ—Ä–∫–µ—Ä–µ
        worker_file_path = f"/app/uploads/{safe_filename}"
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –Ω–∞ –¥–∏—Å–∫
        upload_dir = "/app/uploads"
        os.makedirs(upload_dir, exist_ok=True)
        file_path = os.path.join(upload_dir, safe_filename)
        
        try:
            content = await file.read()
            with open(file_path, 'wb') as f:
                f.write(content)
            
            file_size_mb = len(content) / (1024 * 1024)
            print(f"üì¶ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –Ω–∞ –¥–∏—Å–∫: {file_path} ({file_size_mb:.2f} –ú–ë)")
        except Exception as save_error:
            error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(save_error)}"
            raise HTTPException(status_code=500, detail=error_msg)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –∞—Ä—Ö–∏–≤–æ–º
        is_archive = file.filename.lower().endswith(('.zip', '.gz', '.gzip'))
        
        if is_archive:
            # –®–∞–≥ 2: –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–∞
            update_import_progress('extracting', '–†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–∞...')
            try:
                decoded_content = extract_compressed_file(content, file.filename)
                decoded_size_mb = len(decoded_content.encode('utf-8')) / (1024 * 1024)
                print(f"üîì –ê—Ä—Ö–∏–≤ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω: {decoded_size_mb:.2f} –ú–ë")
            except Exception as extract_error:
                error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–µ –∞—Ä—Ö–∏–≤–∞: {str(extract_error)}"
                update_import_progress('error', error_msg, error_message=error_msg)
                raise HTTPException(status_code=400, detail=error_msg)
        else:
            # –ï—Å–ª–∏ –Ω–µ –∞—Ä—Ö–∏–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–∞–∫ –µ—Å—Ç—å
            decoded_content = content.decode('utf-8-sig')
            decoded_size_mb = len(decoded_content.encode('utf-8')) / (1024 * 1024)
            print(f"üìÑ –§–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∞—Ä—Ö–∏–≤–æ–º: {decoded_size_mb:.2f} –ú–ë")
        
        # –®–∞–≥ 3: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∏ —Ä–∞–∑–¥–µ–ª—è–µ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if decoded_size_mb > 100:
            update_import_progress('splitting', f'–§–∞–π–ª –±–æ–ª—å—à–æ–π ({decoded_size_mb:.1f} –ú–ë), —Ä–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ 100 –ú–ë...')
            try:
                parts = split_file_by_size(decoded_content, 100)
                total_parts = len(parts)
                print(f"‚úÇÔ∏è –§–∞–π–ª —Ä–∞–∑–¥–µ–ª–µ–Ω –Ω–∞ {total_parts} —á–∞—Å—Ç–µ–π –ø–æ 100 –ú–ë")
                update_import_progress('splitting', f'–§–∞–π–ª —Ä–∞–∑–¥–µ–ª–µ–Ω –Ω–∞ {total_parts} —á–∞—Å—Ç–µ–π –ø–æ 100 –ú–ë', total_parts=total_parts)
            except Exception as split_error:
                error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(split_error)}"
                update_import_progress('error', error_msg, error_message=error_msg)
                raise HTTPException(status_code=400, detail=error_msg)
        else:
            # –§–∞–π–ª –Ω–µ –Ω—É–∂–Ω–æ —Ä–∞–∑–¥–µ–ª—è—Ç—å
            parts = [decoded_content]
            total_parts = 1
            update_import_progress('processing', '–§–∞–π–ª –≥–æ—Ç–æ–≤ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ', total_parts=total_parts)
        
        # –®–∞–≥ 4: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–π —á–∞—Å—Ç–∏
        total_records = 0
        total_processed_lines = 0
        db = get_db()
        
        # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞–º—è—Ç—å –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏
        try:
            from main import log_memory_usage
            log_memory_usage()
        except ImportError:
            print("üíæ Memory logging not available")
        
        print(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É {len(parts)} —á–∞—Å—Ç–µ–π —Ñ–∞–π–ª–∞")
        print(f"üìä –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {sum(len(part.encode('utf-8')) for part in parts) / (1024*1024):.2f} –ú–ë")
        
        for part_index, part_content in enumerate(parts, 1):
            try:
                current_part = part_index
                part_start_time = datetime.now()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (–º–∞–∫—Å–∏–º—É–º 30 –º–∏–Ω—É—Ç –Ω–∞ –≤–µ—Å—å –∏–º–ø–æ—Ä—Ç)
                if part_index > 1:
                    total_elapsed = (datetime.now() - import_start_time).total_seconds()
                    if total_elapsed > 1800:  # 30 –º–∏–Ω—É—Ç
                        error_msg = f"–ü—Ä–µ–≤—ã—à–µ–Ω–æ –æ–±—â–µ–µ –≤—Ä–µ–º—è –∏–º–ø–æ—Ä—Ç–∞ (30 –º–∏–Ω—É—Ç). –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {part_index-1} –∏–∑ {total_parts} —á–∞—Å—Ç–µ–π."
                        update_import_progress('error', error_msg, error_message=error_msg)
                        raise HTTPException(status_code=408, detail=error_msg)
                print(f"üìã –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —á–∞—Å—Ç–∏ {current_part} –∏–∑ {total_parts}")
                print(f"üìä –†–∞–∑–º–µ—Ä —á–∞—Å—Ç–∏ {current_part}: {len(part_content.encode('utf-8')) / (1024*1024):.2f} –ú–ë")
                update_import_progress('processing', f'–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ {current_part} –∏–∑ {total_parts}...', 
                                     current_part=current_part)
                
                print(f"üìã –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª {current_part} –∏–∑ {total_parts}")
                
                # –ü–∞—Ä—Å–∏–º —Ç–µ–∫—É—â—É—é —á–∞—Å—Ç—å
                part_lines = part_content.splitlines()
                part_total_lines = len(part_lines)
                
                # –ü–∞—Ä—Å–∏–º CSV —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º ;
                reader = csv.DictReader(part_lines, delimiter=';')
                
                part_records = []
                part_processed_lines = 0
                batch_size = 1000
                start_time = datetime.now()
                
                for row in reader:
                    try:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (–º–∞–∫—Å–∏–º—É–º 10 –º–∏–Ω—É—Ç –Ω–∞ —Ñ–∞–π–ª)
                        if (datetime.now() - start_time).total_seconds() > 600:  # 10 –º–∏–Ω—É—Ç
                            error_msg = f"–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {current_part} (10 –º–∏–Ω—É—Ç). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Ñ–∞–π–ª –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞."
                            update_import_progress('error', error_msg, error_message=error_msg)
                            raise HTTPException(status_code=408, detail=error_msg)
                        
                        # –ü–∞—Ä—Å–∏–º hostname –∏ IP –∏–∑ –ø–æ–ª—è @Host
                        host_info = row['@Host'].strip('"')
                        hostname = host_info.split(' (')[0] if ' (' in host_info else host_info
                        ip_address = host_info.split('(')[1].split(')')[0] if ' (' in host_info else ''
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å IP –∞–¥—Ä–µ—Å–∞
                        if ip_address and not is_valid_ip(ip_address):
                            print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å—å —Å –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–º IP: {ip_address}")
                            part_processed_lines += 1
                            continue
                        
                        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–æ–ª–µ–π
                        cve = row['Host.@Vulners.CVEs'].strip('"')
                        criticality = row['host.UF_Criticality'].strip('"')
                        zone = row['Host.UF_Zone'].strip('"')
                        os_name = row['Host.OsName'].strip('"')
                        status = 'Active'
                        
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å–∏ —Å –ø—É—Å—Ç—ã–º–∏ CVE
                        if not cve or cve == '' or cve == '""':
                            print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å—å —Å –ø—É—Å—Ç—ã–º CVE –¥–ª—è —Ö–æ—Å—Ç–∞: {hostname} ({ip_address})")
                            part_processed_lines += 1
                            continue
                        
                        part_records.append({
                            'hostname': hostname,
                            'ip_address': ip_address,
                            'cve': cve,
                            'cvss': None,
                            'criticality': criticality,
                            'status': status,
                            'os_name': os_name,
                            'zone': zone
                        })
                        
                        part_processed_lines += 1
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ batch_size —Å—Ç—Ä–æ–∫
                        if part_processed_lines % batch_size == 0:
                            update_import_progress('processing', 
                                                 f'–§–∞–π–ª {current_part}/{total_parts}: {part_processed_lines:,}/{part_total_lines:,} —Å—Ç—Ä–æ–∫', 
                                                 processed_records=part_processed_lines, total_records=part_total_lines,
                                                 current_file_records=len(part_records))
                            print(f"üìä –ß–∞—Å—Ç—å {current_part}: {part_processed_lines:,}/{part_total_lines:,} —Å—Ç—Ä–æ–∫, {len(part_records):,} –∑–∞–ø–∏—Å–µ–π")
                        
                    except HTTPException:
                        raise
                    except Exception as row_error:
                        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏ {part_processed_lines} –≤ —Ñ–∞–π–ª–µ {current_part}: {row_error}")
                        part_processed_lines += 1
                        continue
                
                print(f"‚úÖ –§–∞–π–ª {current_part} –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {len(part_records):,} –∑–∞–ø–∏—Å–µ–π")
                
                # –®–∞–≥ 5: –í—Å—Ç–∞–≤–∫–∞ —Ñ–∞–π–ª–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
                print(f"üíæ –ì–æ—Ç–æ–≤–∏–º—Å—è –∫ –≤—Å—Ç–∞–≤–∫–µ {len(part_records):,} –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
                try:
                    log_memory_usage()
                except NameError:
                    print("üíæ Memory logging not available")
                update_import_progress('inserting', f'–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ {current_part} –∏–∑ {total_parts}...', 
                                     current_file_records=len(part_records))
                
                try:
                    print(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º –≤—Å—Ç–∞–≤–∫—É –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö...")
                    await db.insert_hosts_records_with_progress(part_records, update_import_progress)
                    print(f"‚úÖ –í—Å—Ç–∞–≤–∫–∞ –∑–∞–ø–∏—Å–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                    print(f"üíæ –§–∞–π–ª {current_part} —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
                    
                except Exception as db_error:
                    error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {current_part}: {str(db_error)}"
                    update_import_progress('error', error_msg, error_message=error_msg)
                    raise HTTPException(status_code=500, detail=error_msg)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â–∏–µ —Å—á–µ—Ç—á–∏–∫–∏
                total_records += len(part_records)
                total_processed_lines += part_processed_lines
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                update_import_progress('processing', f'–§–∞–π–ª {current_part} –∏–∑ {total_parts} –∑–∞–≤–µ—Ä—à–µ–Ω', 
                                     total_records=total_records, processed_records=total_processed_lines, total_files_processed=current_part)
                
                # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞–º—è—Ç—å –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞—Å—Ç–∏
                try:
                    log_memory_usage()
                except NameError:
                    print("üíæ Memory logging not available")
                
            except HTTPException:
                raise
            except Exception as part_error:
                error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {current_part}: {str(part_error)}"
                update_import_progress('error', error_msg, error_message=error_msg)
                raise HTTPException(status_code=500, detail=error_msg)
        
        # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ
        update_import_progress('completed', '–ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω', total_records=total_records, processed_records=total_processed_lines, 
                              total_files_processed=total_parts)
        print(f"üéâ –ò–º–ø–æ—Ä—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω: {total_records:,} –∑–∞–ø–∏—Å–µ–π –∏–∑ {total_processed_lines:,} —Å—Ç—Ä–æ–∫ –≤ {total_parts} —Ñ–∞–π–ª–∞—Ö")
        
        return {
            "success": True, 
            "count": total_records, 
            "total_processed": total_processed_lines,
            "total_parts": total_parts,
            "message": f"–§–∞–π–ª –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω –Ω–∞ {total_parts} —Ñ–∞–π–ª–æ–≤ –ø–æ 100 –ú–ë –∏ —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω"
        }
        
    except HTTPException:
        # –ü–µ—Ä–µ–±—Ä–∞—Å—ã–≤–∞–µ–º HTTP –∏—Å–∫–ª—é—á–µ–Ω–∏—è –∫–∞–∫ –µ—Å—Ç—å
        raise
    except Exception as e:
        error_msg = f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ: {str(e)}"
        update_import_progress('error', error_msg, error_message=error_msg)
        print(f'‚ùå Hosts upload error: {traceback.format_exc()}')
        raise HTTPException(status_code=500, detail=error_msg)


@router.get("/api/hosts/status")
async def hosts_status():
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Ö–æ—Å—Ç–æ–≤"""
    try:
        db = get_db()
        count = await db.count_hosts_records()
        return {"success": True, "count": count}
    except Exception as e:
        print('Hosts status error:', traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/api/hosts/import-progress")
async def get_import_progress():
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å –∏–º–ø–æ—Ä—Ç–∞ —Ö–æ—Å—Ç–æ–≤"""
    global import_progress
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è
    estimated_time = None
    if (import_progress['start_time'] and 
        import_progress['processed_records'] > 0 and 
        import_progress['total_records'] > 0):
        estimated_time = estimate_remaining_time(
            import_progress['start_time'],
            import_progress['processed_records'],
            import_progress['total_records']
        )
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    overall_progress = 0
    if import_progress['total_records'] > 0:
        overall_progress = min(100, (import_progress['processed_records'] / import_progress['total_records']) * 100)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–º —Ñ–∞–π–ª–µ
    current_file_info = ""
    if import_progress['current_part'] and import_progress['total_parts']:
        current_file_info = f"–§–∞–π–ª {import_progress['current_part']} –∏–∑ {import_progress['total_parts']}"
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —à–∞–≥–∞
    detailed_step = import_progress['current_step']
    if current_file_info:
        detailed_step = f"{current_file_info}: {import_progress['current_step']}"
    
    return {
        "status": import_progress['status'],
        "current_step": detailed_step,
        "progress": overall_progress,
        "total_steps": import_progress['total_steps'],
        "current_step_progress": import_progress['current_step_progress'],
        "total_records": import_progress['total_records'],
        "processed_records": import_progress['processed_records'],
        "error_message": import_progress['error_message'],
        "estimated_time": estimated_time,
        "total_parts": import_progress['total_parts'],
        "current_part": import_progress['current_part'],
        "total_files_processed": import_progress['total_files_processed'],
        "current_file_records": import_progress['current_file_records'],
        "current_file_info": current_file_info,
        "overall_progress": overall_progress
    }


@router.get("/api/hosts/import-limits")
async def get_import_limits():
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ª–∏–º–∏—Ç–∞—Ö –∏–º–ø–æ—Ä—Ç–∞"""
    return {
        "max_file_size_mb": 1024,  # 1GB
        "max_processing_time_minutes": 10,
        "recommended_file_size_mb": 100,
        "auto_split_size_mb": 100,
        "message": "–§–∞–π–ª—ã –±–æ–ª—å—à–µ 100 –ú–ë –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞–∑–¥–µ–ª—è—é—Ç—Å—è –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ 100 –ú–ë"
    }


@router.get("/api/hosts/search")
async def search_hosts(
    hostname: str = None,
    cve: str = None,
    ip_address: str = None,
    criticality: str = None,
    exploits_only: bool = False,
    epss_only: bool = False,
    sort_by: str = None,
    limit: int = 100,
    page: int = 1
):
    """–ü–æ–∏—Å–∫ —Ö–æ—Å—Ç–æ–≤"""
    try:
        db = get_db()
        results, total_count = await db.search_hosts(hostname, cve, ip_address, criticality, exploits_only, epss_only, sort_by, limit, page)
        return {
            "success": True, 
            "results": results,
            "total_count": total_count,
            "page": page,
            "limit": limit,
            "total_pages": (total_count + limit - 1) // limit
        }
    except Exception as e:
        print('Hosts search error:', traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))





@router.post("/api/hosts/update-data-background")
async def start_background_update():
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å —Ñ–æ–Ω–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Ö–æ—Å—Ç–æ–≤"""
    try:
        db = get_db()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∑–∞–ø—É—â–µ–Ω–∞ –ª–∏ —É–∂–µ –∑–∞–¥–∞—á–∞
        existing_task = await db.get_background_task('hosts_update')
        if existing_task and existing_task['status'] in ['processing', 'initializing']:
            return {"success": False, "message": "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ"}
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
        task_id = await db.create_background_task('hosts_update')
        
        def progress_callback(status, step, **kwargs):
            # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–¥–∞—á—É –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
            asyncio.create_task(db.update_background_task(task_id, 
                status=status, 
                current_step=step,
                total_items=kwargs.get('total_cves', 0),
                processed_items=kwargs.get('processed_cves', 0),
                total_records=kwargs.get('total_hosts', 0),
                updated_records=kwargs.get('updated_hosts', 0)
            ))
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
        result = await db.update_hosts_epss_and_exploits_background(progress_callback)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        if result['success']:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –±—ã–ª–∞ –ª–∏ –∑–∞–¥–∞—á–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞
            if '–æ—Ç–º–µ–Ω–µ–Ω–æ' in result.get('message', '').lower():
                await db.update_background_task(task_id, 
                    status='cancelled', 
                    current_step='–û—Ç–º–µ–Ω–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º',
                    total_items=result.get('processed_cves', 0),
                    processed_items=result.get('processed_cves', 0),
                    total_records=result.get('updated_count', 0),
                    updated_records=result.get('updated_count', 0)
                )
            else:
                await db.update_background_task(task_id, 
                    status='completed', 
                    current_step='–ó–∞–≤–µ—Ä—à–µ–Ω–æ',
                    total_items=result.get('processed_cves', 0),
                    processed_items=result.get('processed_cves', 0),
                    total_records=result.get('updated_count', 0),
                    updated_records=result.get('updated_count', 0)
                )
        else:
            await db.update_background_task(task_id, 
                status='error', 
                current_step='–û—à–∏–±–∫–∞',
                error_message=result.get('message', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')
            )
        
        return result
        
    except Exception as e:
        print('Background update error:', traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/api/hosts/update-data-progress")
async def get_background_update_progress():
    """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å —Ñ–æ–Ω–æ–≤–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"""
    try:
        db = get_db()
        task = await db.get_background_task('hosts_update')
        
        if not task:
            return {
                "status": "idle",
                "current_step": "–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á",
                "total_cves": 0,
                "processed_cves": 0,
                "total_hosts": 0,
                "updated_hosts": 0,
                "progress_percent": 0,
                "estimated_time_seconds": None,
                "start_time": None,
                "error_message": None
            }
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è
        estimated_time = None
        if (task['start_time'] and 
            task['processed_items'] > 0 and 
            task['total_items'] > 0):
            
            elapsed = (datetime.now() - task['start_time']).total_seconds()
            if elapsed > 0:
                rate = task['processed_items'] / elapsed
                remaining_items = task['total_items'] - task['processed_items']
                estimated_time = remaining_items / rate if rate > 0 else None
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        progress_percent = 0
        if task['total_items'] > 0:
            progress_percent = (task['processed_items'] / task['total_items']) * 100
        
        return {
            "status": task['status'],
            "current_step": task['current_step'] or "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è...",
            "total_cves": task['total_items'],
            "processed_cves": task['processed_items'],
            "total_hosts": task['total_records'],
            "updated_hosts": task['updated_records'],
            "progress_percent": round(progress_percent, 1),
            "estimated_time_seconds": estimated_time,
            "start_time": task['start_time'].isoformat() if task['start_time'] else None,
            "error_message": task['error_message']
        }
    except Exception as e:
        print('Error getting background update progress:', e)
        return {
            "status": "error",
            "current_step": "–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞",
            "total_cves": 0,
            "processed_cves": 0,
            "total_hosts": 0,
            "updated_hosts": 0,
            "progress_percent": 0,
            "estimated_time_seconds": None,
            "start_time": None,
            "error_message": str(e)
        }


@router.post("/api/hosts/update-data-cancel")
async def cancel_background_update():
    """–û—Ç–º–µ–Ω–∏—Ç—å —Ñ–æ–Ω–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
    try:
        db = get_db()
        
        # –û—Ç–º–µ–Ω—è–µ–º –∑–∞–¥–∞—á—É –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        cancelled = await db.cancel_background_task('hosts_update')
        
        if cancelled:
            return {"success": True, "message": "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ"}
        else:
            return {"success": False, "message": "–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"}
    except Exception as e:
        print('Error cancelling background update:', e)
        return {"success": False, "message": f"–û—à–∏–±–∫–∞ –æ—Ç–º–µ–Ω—ã: {str(e)}"}


@router.post("/api/hosts/update-data-background-parallel")
async def start_background_update_parallel():
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å —Ñ–æ–Ω–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Ö–æ—Å—Ç–æ–≤ —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
    try:
        db = get_db()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∑–∞–ø—É—â–µ–Ω–∞ –ª–∏ —É–∂–µ –∑–∞–¥–∞—á–∞
        existing_task = await db.get_background_task('hosts_update')
        if existing_task and existing_task['status'] in ['processing', 'initializing']:
            return {"success": False, "message": "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ"}
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
        task_id = await db.create_background_task('hosts_update')
        
        def progress_callback(status, step, **kwargs):
            # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–¥–∞—á—É –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
            asyncio.create_task(db.update_background_task(task_id, 
                status=status, 
                current_step=step,
                total_items=kwargs.get('total_cves', 0),
                processed_items=kwargs.get('processed_cves', 0),
                total_records=kwargs.get('total_hosts', 0),
                updated_records=kwargs.get('updated_hosts', 0)
            ))
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —Ñ–æ–Ω–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
        result = await db.update_hosts_complete(progress_callback)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        if result['success']:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –±—ã–ª–∞ –ª–∏ –∑–∞–¥–∞—á–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞
            if '–æ—Ç–º–µ–Ω–µ–Ω–æ' in result.get('message', '').lower():
                await db.update_background_task(task_id, 
                    status='cancelled', 
                    current_step='–û—Ç–º–µ–Ω–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º',
                    total_items=result.get('processed_cves', 0),
                    processed_items=result.get('processed_cves', 0),
                    total_records=result.get('updated_count', 0),
                    updated_records=result.get('updated_count', 0)
                )
            else:
                await db.update_background_task(task_id, 
                    status='completed', 
                    current_step='–ó–∞–≤–µ—Ä—à–µ–Ω–æ',
                    total_items=result.get('processed_cves', 0),
                    processed_items=result.get('processed_cves', 0),
                    total_records=result.get('updated_count', 0),
                    updated_records=result.get('updated_count', 0)
                )
        else:
            await db.update_background_task(task_id, 
                status='error', 
                current_step='–û—à–∏–±–∫–∞',
                error_message=result.get('message', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')
            )
        
        return result
        
    except Exception as e:
        print('Background update error:', traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/api/hosts/{host_id}/risk")
async def calculate_host_risk(host_id: int):
    """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å —Ä–∏—Å–∫ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ö–æ—Å—Ç–∞"""
    try:
        db = get_db()
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ö–æ—Å—Ç–∞
        host_data = await db.get_host_by_id(host_id)
        if not host_data:
            raise HTTPException(status_code=404, detail="–•–æ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        try:
            with open("data/settings.json", "r", encoding="utf-8") as f:
                import json
                settings = json.load(f)
        except FileNotFoundError:
            settings = {
                "impact_resource_criticality": "Medium",
                "impact_confidential_data": "–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç",
                "impact_internet_access": "–ù–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
            }
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∏—Å–∫
        risk_result = calculate_risk_score(
            host_data.get('epss'),
            host_data.get('cvss'),
            settings
        )
        
        return {
            "success": True,
            "host_id": host_id,
            "hostname": host_data.get('hostname'),
            "cve": host_data.get('cve'),
            "epss": host_data.get('epss'),
            "cvss": host_data.get('cvss'),
            "risk_calculation": risk_result
        }
    except HTTPException:
        raise
    except Exception as e:
        print('Host risk calculation error:', traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/api/hosts/export")
async def export_hosts(
    hostname: str = None,
    cve: str = None,
    ip_address: str = None,
    criticality: str = None,
    exploits_only: bool = False,
    epss_only: bool = False
):
    """–≠–∫—Å–ø–æ—Ä—Ç —Ö–æ—Å—Ç–æ–≤ –≤ Excel"""
    try:
        db = get_db()
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ö–æ—Å—Ç–æ–≤
        hosts_data = await db.search_hosts(hostname, cve, ip_address, criticality, exploits_only, epss_only)
        
        if not hosts_data:
            raise HTTPException(status_code=404, detail="–î–∞–Ω–Ω—ã–µ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        # –°–æ–∑–¥–∞–µ–º Excel —Ñ–∞–π–ª
        excel_file = create_excel_file(hosts_data)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ–∞–π–ª –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        return StreamingResponse(
            excel_file,
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            headers={"Content-Disposition": "attachment; filename=hosts_export.xlsx"}
        )
    except HTTPException:
        raise
    except Exception as e:
        print('Hosts export error:', traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/api/hosts/export-report")
async def export_hosts_report(
    format: str = "excel",
    filters: dict = None,
    include_charts: bool = True
):
    """–≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–∞ –ø–æ —Ö–æ—Å—Ç–∞–º"""
    try:
        db = get_db()
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
        where_conditions = []
        params = []
        param_count = 0
        
        if filters:
            if filters.get('hostname'):
                param_count += 1
                where_conditions.append(f"hostname ILIKE ${param_count}")
                params.append(f"%{filters['hostname']}%")
            
            if filters.get('cve'):
                param_count += 1
                where_conditions.append(f"cve ILIKE ${param_count}")
                params.append(f"%{filters['cve']}%")
            
            if filters.get('criticality'):
                param_count += 1
                where_conditions.append(f"criticality = ${param_count}")
                params.append(filters['criticality'])
            
            if filters.get('min_risk'):
                param_count += 1
                where_conditions.append(f"risk_score >= ${param_count}")
                params.append(filters['min_risk'])
            
            if filters.get('has_exploits'):
                where_conditions.append("has_exploits = TRUE")
        
        where_clause = " AND ".join(where_conditions) if where_conditions else "1=1"
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        query = f"""
            SELECT 
                hostname, ip_address, cve, cvss, cvss_source, criticality, 
                status, os_name, zone, epss_score, epss_percentile, 
                risk_score, exploits_count, has_exploits, last_exploit_date,
                epss_updated_at, exploits_updated_at, risk_updated_at
            FROM vulnanalizer.hosts 
            WHERE {where_clause}
            ORDER BY risk_score DESC NULLS LAST, hostname, cve
        """
        
        conn = await db.get_connection()
        rows = await conn.fetch(query, *params)
        
        if format.lower() == "excel":
            # –°–æ–∑–¥–∞–µ–º Excel —Ñ–∞–π–ª
            from services.excel_service import create_excel_report
            
            filename = f"vulnanalizer_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
            file_path = await create_excel_report(rows, filename, include_charts)
            
            return FileResponse(
                file_path,
                media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                filename=filename
            )
        
        elif format.lower() == "csv":
            # –°–æ–∑–¥–∞–µ–º CSV —Ñ–∞–π–ª
            import csv
            import tempfile
            
            filename = f"vulnanalizer_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            temp_file = tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.csv')
            
            with temp_file:
                writer = csv.writer(temp_file)
                # –ó–∞–≥–æ–ª–æ–≤–∫–∏
                writer.writerow([
                    'Hostname', 'IP Address', 'CVE', 'CVSS', 'CVSS Source', 
                    'Criticality', 'Status', 'OS', 'Zone', 'EPSS Score', 
                    'EPSS Percentile', 'Risk Score', 'Exploits Count', 
                    'Has Exploits', 'Last Exploit Date'
                ])
                
                # –î–∞–Ω–Ω—ã–µ
                for row in rows:
                    writer.writerow([
                        row['hostname'], row['ip_address'], row['cve'], 
                        row['cvss'], row['cvss_source'], row['criticality'],
                        row['status'], row['os_name'], row['zone'], 
                        row['epss_score'], row['epss_percentile'], row['risk_score'],
                        row['exploits_count'], row['has_exploits'], row['last_exploit_date']
                    ])
            
            return FileResponse(
                temp_file.name,
                media_type="text/csv",
                filename=filename
            )
        
        elif format.lower() == "json":
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º JSON
            return {
                "success": True,
                "data": [dict(row) for row in rows],
                "total_count": len(rows),
                "exported_at": datetime.now().isoformat()
            }
        
        else:
            raise HTTPException(status_code=400, detail="–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞")
            
    except Exception as e:
        print(f"Error exporting report: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/api/hosts/clear")
async def clear_hosts():
    """–û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ –∑–∞–ø–∏—Å–∏ —Ö–æ—Å—Ç–æ–≤"""
    try:
        db = get_db()
        await db.clear_hosts()
        return {"success": True, "message": "–í—Å–µ –∑–∞–ø–∏—Å–∏ —Ö–æ—Å—Ç–æ–≤ —É–¥–∞–ª–µ–Ω—ã"}
    except Exception as e:
        print('Hosts clear error:', traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/api/hosts/clean-empty-cve")
async def clean_empty_cve():
    """–û—á–∏—Å—Ç–∏—Ç—å –∑–∞–ø–∏—Å–∏ —Å –ø—É—Å—Ç—ã–º–∏ CVE –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    try:
        db = get_db()
        conn = await db.get_connection()
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π —Å –ø—É—Å—Ç—ã–º–∏ CVE
        count_query = """
            SELECT COUNT(*) as cnt 
            FROM vulnanalizer.hosts 
            WHERE cve IS NULL OR cve = '' OR cve = '""'
        """
        count_result = await conn.fetchrow(count_query)
        empty_cve_count = count_result['cnt'] if count_result else 0
        
        if empty_cve_count == 0:
            return {
                "success": True,
                "message": "–ó–∞–ø–∏—Å–µ–π —Å –ø—É—Å—Ç—ã–º–∏ CVE –Ω–µ –Ω–∞–π–¥–µ–Ω–æ",
                "deleted_count": 0
            }
        
        # –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å–∏ —Å –ø—É—Å—Ç—ã–º–∏ CVE
        delete_query = """
            DELETE FROM vulnanalizer.hosts 
            WHERE cve IS NULL OR cve = '' OR cve = '""'
        """
        await conn.execute(delete_query)
        
        # –ü–æ–ª—É—á–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
        total_query = "SELECT COUNT(*) as cnt FROM vulnanalizer.hosts"
        total_result = await conn.fetchrow(total_query)
        total_count = total_result['cnt'] if total_result else 0
        
        await db.release_connection(conn)
        
        return {
            "success": True,
            "message": f"–£–¥–∞–ª–µ–Ω–æ {empty_cve_count} –∑–∞–ø–∏—Å–µ–π —Å –ø—É—Å—Ç—ã–º–∏ CVE",
            "deleted_count": empty_cve_count,
            "remaining_count": total_count
        }
        
    except Exception as e:
        print(f"Error cleaning empty CVE records: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –∑–∞–ø–∏—Å–µ–π —Å –ø—É—Å—Ç—ã–º–∏ CVE: {str(e)}")


@router.get("/api/hosts/empty-cve-count")
async def get_empty_cve_count():
    """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π —Å –ø—É—Å—Ç—ã–º–∏ CVE"""
    try:
        db = get_db()
        conn = await db.get_connection()
        
        count_query = """
            SELECT COUNT(*) as cnt 
            FROM vulnanalizer.hosts 
            WHERE cve IS NULL OR cve = '' OR cve = '""'
        """
        count_result = await conn.fetchrow(count_query)
        empty_cve_count = count_result['cnt'] if count_result else 0
        
        # –ü–æ–ª—É—á–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
        total_query = "SELECT COUNT(*) as cnt FROM vulnanalizer.hosts"
        total_result = await conn.fetchrow(total_query)
        total_count = total_result['cnt'] if total_result else 0
        
        await db.release_connection(conn)
        
        return {
            "success": True,
            "empty_cve_count": empty_cve_count,
            "total_count": total_count,
            "percentage": (empty_cve_count / total_count * 100) if total_count > 0 else 0
        }
        
    except Exception as e:
        print(f"Error getting empty CVE count: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {str(e)}")
